# EU AI Act Engineering

This repository provides the reference list for the emerging term "AI Act Engineering". 

**[EU AI Act](https://artificialintelligenceact.eu/)** regulates the development, deployment, and use of AI systems within the European Union. It aims to promote *trustworthy AI* by mitigating risks and ensuring fundamental rights are protected.

We define the term **"AI Act Engineering"** as a set of engineering practices, processes, and methodologies needed to develop and deploy AI systems that comply with the requirements of the proposed European Union (EU) AI Act.

Engineering for the EU AI Act Compliance involves the following aspects:

 - **Risk Assessment:** Classifying AI systems based on their risk level (*unacceptable, high, limited, low*) as defined by the Act.
 - **Mitigating High Risks:** For high-risk systems, implementing safeguards like robust data management, human oversight mechanisms, and explainable AI techniques.
 - **Documentation and Transparency:** Properly documenting the AI system's development process and ensuring a level of transparency appropriate for the risk level

## Reading List
1. [A Machine Learning Engineerâ€™s Guide To The AI Act](https://www.forbes.com/sites/forbeseq/2023/06/15/a-machine-learning-engineers-guide-to-the-ai-act/)

### Risk Assessment

1. [Method for (AI System) Risk Classification](https://miro.com/app/board/uXjVOz16ydQ=/)

### Mitigating High Risks

1. [AI safety](https://github.com/elicit/machine-learning-list?tab=readme-ov-file#ai-safety)
