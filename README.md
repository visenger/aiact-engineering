# EU AI Act Engineering

This repository provides the reference list for the emerging term "AI Act Engineering". 

**[EU AI Act](https://artificialintelligenceact.eu/)** regulates the development, deployment, and use of AI systems within the European Union. It aims to promote *trustworthy AI* by mitigating risks and ensuring fundamental rights are protected.

We define the term **"AI Act Engineering"** as a set of engineering practices, processes, and methodologies needed to develop and deploy AI systems that comply with the requirements of the proposed European Union (EU) AI Act.

Engineering for the EU AI Act Compliance involves the following aspects:

 - **Risk Assessment:** Classifying AI systems based on their risk level (*unacceptable, high, limited, low*) as defined by the EU AI Act.
 - **Mitigating High Risks:** For high-risk systems, implementing safeguards like robust data management, human oversight mechanisms, and explainable AI techniques. Engineering AI systems under the EU AI Act would require robust testing and validation to ensure that they meet safety, accuracy, and reliability standards. This might include implementing and documenting extensive risk assessments, mitigation strategies, and quality control measures.
 - **Documentation and Transparency:** Properly documenting the AI system's development process and ensuring a level of transparency appropriate for the risk level. Developers would need to maintain detailed records of AI training data, algorithms, and processes to meet transparency requirements. This documentation would be crucial for audits and for providing explanations of AI system decisions when necessary.

## Reading List
1. [The AI Engineer's Guide to Surviving the EU AI Act. By Larysa Visengeriyeva](https://learning.oreilly.com/library/view/the-ai-engineers/9781098172480/)
2. [A Machine Learning Engineerâ€™s Guide To The AI Act](https://www.forbes.com/sites/forbeseq/2023/06/15/a-machine-learning-engineers-guide-to-the-ai-act/)

### Risk Assessment

1. [Method for (AI System) Risk Classification](https://miro.com/app/board/uXjVOz16ydQ=/)

### Mitigating High Risks

1. [AI safety](https://github.com/elicit/machine-learning-list?tab=readme-ov-file#ai-safety)
1. [AI Trust Lab: Engineering for Trustworthy AI (CMU)](https://www.sei.cmu.edu/our-work/projects/display.cfm?customel_datapageid_4050=197910)
1. [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/)
1.[Guidelines for secure AI system development](https://www.ncsc.govt.nz/assets/Uploads/Guidelines-for-secure-AI-system-development-v2.pdf)

### Documentation and Transparency

1. [Model Cards for Model Reporting (paper)](https://arxiv.org/pdf/1810.03993.pdf)
1. [Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit)

### AI Act Engineering Tooling Landscape

1. [The LF AI & Data Foundation](https://lfaidata.foundation/projects/)
1. [GenAI Infra Stack](https://sapphireventures.com/blog/building-the-future-a-deep-dive-into-the-generative-ai-app-infrastructure-stack/)
1. [GenAI App Stack](https://github.com/a16z-infra/llm-app-stack)
1. [AI Infrastructure Stack](https://ai-infrastructure.org/ai-infrastructure-landscape/)
1. [The 2024 MAD (Machine Learning, AI and Data) Landscape](https://mattturck.com/mad2024/)
1. [The State of Data Engineering](https://lakefs.io/blog/the-state-of-data-engineering-2024/#)
1. [ML Testing Landscape](https://www.efemarai.com/post/machine-learning-testing-landscape )

### AI Engineering 
1. [LLM engineer handbook](https://github.com/SylphAI-Inc/LLM-engineer-handbook)

